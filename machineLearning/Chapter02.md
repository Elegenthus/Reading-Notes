### Chapter02 模型评估与选择
---
* 经验误差与过拟合
    * 概念
        * 精度：1-错误率
        * 误差：学习器的实际预测输出与样本的真实输出之间的差异
        * 训练误差/经验误差：学习器在训练集上的误差
        * 泛化误差：在新样本上的误差
    * 学习器
        * 目的：从训练样本中尽可能学习出适用于所有潜在样本的“普遍规律”
        * 过拟合：当学习器把样本训练的太好的时候，可能把训练集本身的一些特点当做是所有潜在样本都具有的一般性质
        * 欠拟合：对于训练样本的一般性质还未掌握好
        * 过拟合是机器学习面临的关键障碍，无法彻底避免，只能缓解

* 评估方法
    * 留出法(hold-out)
        * 概念：直接将数据集划分为两个互斥的集合，其中一个集合作为训练集，另一个作为测试集
        * 做法：在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。
        * 训练集数量划分问题：将大约2/3~4/5的样本用于训练，剩余样本用于测试。
    * 交叉验证法/k折交叉验证(cross validation)
        * 概念：将数据集D划分为k个大小相等的子集，每个子集都尽可能保持数据分布的一致性，然后将k-1个子集的并集作为训练集，剩下的那个子集作为测试集，最终返回的是这k个子集的均值。
        * 特殊情况：留一法
            * 概念：每个子集中只包含一个样本
            * 优点：结果比较准确
            * 缺点：数据集较大时，计算开销难以忍受
    * 自助法(bootstrapping)
        * 概念：给定包含m个样本的数据集D，每次随机从D中挑选一个样本，将其拷贝放入D'中，再将该样本放回原来的数据集中，使得其仍然有下一次被挑选出来的可能性，将D'作为训练集，D/D'作为测试集，其数量大约占1/3——这样的测试结果称为包外估计(out-of-bag estimate)。
        * 优点：能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处
        * 缺点：改变了初始数据集的分布，会引入估计偏差
        * 在初始数据量足够时，留出法和交叉验证法更常用一些。
    * 调参与最终模型
        * 为每个参数选定一个变化范围和步长
* 性能度量
    * 对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需要有衡量泛化能力的评价标准，这就是性能度量
        * 回归任务——均方误差
        * 错误率与精度
            * 精度 = 1 - 错误率
        * 查准率、查全率与F1
            * 查准率：选出来的样本是正例的概率
            * 查全率：所有的正例被选出来的概率
            * P-R图：查准率为纵轴，查全率为横轴
                * 若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，可以断言后者的性能优于前者。
                * “平衡点”：“查准率=查全率”时的取值。
            * F1度量
                * 引入参数β，能表达出对查准率/查全率的不同偏好
            * 多个查准率和查全率的均值
            * 先计算查准率、查全率再平均 -> 宏查准率、宏查全率、宏F1
            * 先将各个混淆矩阵的对应元素进行平均，再计算查准率查全率 -> 微查准率、微查全率、微F1
        * ROC和AUC
            * ROC：纵轴-真正例率-所有瓜中好瓜的概率，横轴-假正例率-真正选出来瓜中的好瓜的概率
                * 若一个学习器的ROC曲线被另一个学习器的曲线完全包住，则可断言后者的性能优于前者
            * AUC：ROC曲线下的面积
    * 代价敏感错误率和代价曲线
        * 为权衡不同类型错误所造成的不同损失，可以为错误赋予“非均等代价”。
        * 最小化总体代价
* 比较检验
    * **假设检验**
    * **交叉验证t验证**
    * **McNemar检验**
    * **Friedman检验与Nemenyi后续检验**
* 偏差与方差
    * 解释学习算法泛化性能的一种重要工具
    * 泛化误差 = 偏差 + 方差 + 噪声
    * 偏差：度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力
    * 方差：度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的影响
    * 噪声：表达了当前学习任务上任何学习算法所能到达的期望泛化误差的下界，刻画了学习问题本身的难度